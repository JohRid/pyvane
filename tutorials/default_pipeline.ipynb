{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyVesTo\n",
    "\n",
    "Python Blood Vessel Topology Analysis (PyVesTo) is a framework for analysing blood vessel digital images. This includes the segmentation, representation and characterization of blood vessels. The framework identifies 2D and 3D vascular systems and represent them using graphs. The graphs describe the topology of the blood vessels, that is, bifurcations and terminations are represented as nodes and two nodes are connected if there is a blood vessel segment between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of PyVesTo usage\n",
    "## Using the default pipeline to perform blood vessel morphometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "path = Path(os.path.abspath(''))\n",
    "sys.path.append(str(path.parents[0]))\n",
    "\n",
    "from pyvesto import pipeline, image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important parameters:\n",
    "* ***channel (int)***: Channel to be processed. If None, all image data will be considered.\n",
    "* ***name_filter (function)***: Here you can pass a function for filtering files. This function should return True if the file should be processed, and False otherwise. If name_filter == None, all image files will be processed.\n",
    "* ***save_steps (tuple of str)***: A tuple of strings containing which intermediate data should be saved on disk.  The default behaviour (save_steps == 'all') is to save all intermediate steps: ('segmentation', 'skeletonization', 'network', 'analysis').\n",
    "* ***start_at (int)***: Given the list of images to be processed, start at this index. If 0 or None, all images will be processed.\n",
    "* ***verbosity (int)***: Level of verbosity (0, 1, 2, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = None\n",
    "name_filter = None\n",
    "save_steps = 'all'\n",
    "start_at = 0\n",
    "verbosity = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***img_reader***, is the function used to read the image given a filename. The default image reader used in PyVesTo is located in ***pipeline.read_and_adjust_img***. This function receives a filename (Path or str) and reads the image using the ***img_io*** utility functions. After reading, the data is transformed to float, the linear transformation \\[min, max\\] -> \\[0, 255\\] is applied, and finally the image is interpolated to make it isotropic. The function returns an ***image.Image*** object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_reader = partial(pipeline.read_and_adjust_img, channel=channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A PyVesTo morphometry pipeline is built through the class ***pipeline.BasePipeline***. Here, three parameters are needed:\n",
    "* ***input_path***: Folder containing the input images (Path or str)\n",
    "* ***output_path***: Folder to save images generated from intermediate steps (Path or str)\n",
    "* ***img_reader***: The image reader that will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = Path('../data/images')\n",
    "output_path = Path('../data/results')\n",
    "\n",
    "dp = pipeline.BasePipeline(input_path, img_reader, output_path=output_path, \n",
    "                           name_filter=name_filter, save_steps=save_steps, start_at=start_at, verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyVesTo works with a sequence of subroutines that we call **processors**. Each processor performs a distinct step in the morphometry pipeline. In total, four processors are required: A segmenter, a skeleton builder, a network builder, and an analyzer. PyVesTo already has implemented four default processors that can be used in the aforementioned steps. These processors comprises the methodologies used in recent publications (listed [here](https://github.com/chcomin/pyvesto))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "sigma = None\n",
    "\n",
    "segmenter = pipeline.DefaultSegmenter(threshold, sigma)\n",
    "skeleton_builder = pipeline.DefaultSkeletonBuilder()\n",
    "network_builder = pipeline.DefaultNetworkBuilder()\n",
    "analyzer = pipeline.DefaultAnalyzer(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defined the processors that will be used, they should be added to the BasePipeline object through ***pipeline.BasePipeline.set_processors***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp.set_processors(segmenter, skeleton_builder, network_builder, analyzer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After these steps, the whole pipeline can be executed through ***pipeline.BasePipeline.run***. The obtained results will be saved on the ***output_path*** folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file AVG_40 S1 layer IV (1 of 1)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AVG_40 S1 layer IV': {'Length (mm/mm^3)': 62.93855587801143,\n",
       "  'Branching points (1/mm^3)': 2204.589020896528,\n",
       "  'Tortuosity': 0.29562741674406673}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building your own processors\n",
    "\n",
    "The main reason PyVesTo breaks the morphometry pipeline into four processors, is to able the user writing its own processor as needed. Therefore, one can write a custom segmenter and still use the rest of our default pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All PyVesTo processors should inherit the class ***pipeline.BaseProcessor***. This class implement a \\_\\_call\\_\\_() method that calls ***apply()*** when a ***pipeline.BaseProcessor*** instance is called as a function. Therefore a custom processor can be writen inheriting ***pipeline.BaseProcessor*** and overriding the ***apply()*** method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.ndimage as ndi\n",
    "\n",
    "class CustomSegmenter(pipeline.BaseProcessor):\n",
    "    def __init__(self, threshold=0, radius=40):\n",
    "        # Initialize your variables as you need\n",
    "        self.threshold = threshold\n",
    "        self.radius = radius\n",
    "    \n",
    "    def apply(self, img, file=None):\n",
    "        # Your segmentation code goes here\n",
    "        \n",
    "        # This is a much simpler version of segmentation.vessel_segmentation\n",
    "        # for explaining purposes\n",
    "        \n",
    "        img_data = img.data.astype(np.float)\n",
    "        img_blurred = ndi.gaussian_filter(img_data, sigma=self.radius/2.)\n",
    "        img_corr = img_data - img_blurred\n",
    "        img_bin = img_corr > self.threshold\n",
    "        img_bin = image.Image(img_bin, path=img.path, pix_size=img.pix_size)\n",
    "        \n",
    "        return img_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can define a BasePipeline with the same parameters as before, only changing the segmenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_p = pipeline.BasePipeline(input_path, img_reader, output_path=output_path, name_filter=name_filter, \n",
    "                          start_at=start_at, verbosity=verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = CustomSegmenter()\n",
    "skeleton_builder = pipeline.DefaultSkeletonBuilder()\n",
    "network_builder = pipeline.DefaultNetworkBuilder()\n",
    "analyzer = pipeline.DefaultAnalyzer(10)\n",
    "\n",
    "custom_p.set_processors(segmenter, skeleton_builder, network_builder, analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file AVG_40 S1 layer IV (1 of 1)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'AVG_40 S1 layer IV': {'Length (mm/mm^3)': 70.63979558452819,\n",
       "  'Branching points (1/mm^3)': 2834.5656386922815,\n",
       "  'Tortuosity': 0.3526943147370302}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_p.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
